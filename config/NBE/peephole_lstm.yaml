# Hydra configuration for peephole LSTM training (moved under config/NBE)

# Data settings
train_dir: /workspace/dataset/bin/toy_all_model/train
val_dir: /workspace/dataset/bin/toy_all_model/valid
node_id: 1
global_normalize: False

preload: false
glob: "*.feather"
alpha: 8.0

# Dataloader
batch_size: 64
num_workers: 2

# Model
hidden_size: 256
num_layers: 2
dropout: 0.0
output_size: null

# Optimization
lr: 0.001
weight_decay: 0.0
epochs: 300

# LR / early stopping
lr_patience: 10
lr_factor: 0.9
min_lr: 1e-6
max_lr_reductions: 10
early_stop_patience: 15

# Misc
save_dir: NBE/peepholeLSTM_Local
seed: 42
